{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdT2Jpp1__jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import string\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MDotKFiAGby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f7302d4-3d4a-4c6b-99ae-35e5f046ae40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inv3O3J2A8_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "outputId": "169213fa-0618-4568-83d1-230f4fdc9f64"
      },
      "source": [
        "trainCSV = '/content/drive/My Drive/nlp assignment 3/train.csv'\n",
        "test_csv_path = '/content/drive/My Drive/nlp assignment 3/test.csv'\n",
        "\n",
        "trainDataFrame = pd.read_csv(trainCSV, delimiter=\"\\t\")\n",
        "testDataFrame = pd.read_csv(test_csv_path, delimiter=\"\\t\")\n",
        "print((trainDataFrame))\n",
        "print(testDataFrame)\n",
        "trainDataFrame.head()\n",
        "testDataFrame.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 meta  uid sentiment\n",
            "0                meta    3  negative\n",
            "1                   @    O       NaN\n",
            "2       AdilNisarButt  Hin       NaN\n",
            "3            pakistan  Hin       NaN\n",
            "4                  ka  Hin       NaN\n",
            "...               ...  ...       ...\n",
            "367339           kuch  Hin       NaN\n",
            "367340            bhi  Hin       NaN\n",
            "367341           nahi  Hin       NaN\n",
            "367342        karenge  Hin       NaN\n",
            "367343              .    O       NaN\n",
            "\n",
            "[367344 rows x 3 columns]\n",
            "                  meta  uid sentiment\n",
            "0                 meta    8   neutral\n",
            "1                   RT  Eng       NaN\n",
            "2                    @    O       NaN\n",
            "3      UAAPconfessions  Eng       NaN\n",
            "4                 Love  Eng       NaN\n",
            "...                ...  ...       ...\n",
            "50083               ko  Hin       NaN\n",
            "50084               ..    O       NaN\n",
            "50085            Shame  Eng       NaN\n",
            "50086               on  Eng       NaN\n",
            "50087              mla  Hin       NaN\n",
            "\n",
            "[50088 rows x 3 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meta</th>\n",
              "      <th>uid</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>meta</td>\n",
              "      <td>8</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UAAPconfessions</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Love</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              meta  uid sentiment\n",
              "0             meta    8   neutral\n",
              "1               RT  Eng       NaN\n",
              "2                @    O       NaN\n",
              "3  UAAPconfessions  Eng       NaN\n",
              "4             Love  Eng       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKRXf0G_Bhg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "b3d592b0-ef09-4f61-e827-6e328fcd33ee"
      },
      "source": [
        "#data visualization\n",
        "print(\"Shape of the train data (rows, columns) = \",trainDataFrame.shape)\n",
        "print(\"Shape of the test data (rows, columns) = \",testDataFrame.shape)\n",
        "print(trainDataFrame.size)\n",
        "print(testDataFrame.size)\n",
        "print(\"distribution of train data in sentiments is shown in chart below\")\n",
        "trainDataFrame['sentiment'].value_counts().plot(kind='bar')\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the train data (rows, columns) =  (367344, 3)\n",
            "Shape of the test data (rows, columns) =  (50088, 3)\n",
            "1102032\n",
            "150264\n",
            "distribution of train data in sentiments is shown in chart below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff48b29cdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEaCAYAAAD9iIezAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUNfkjpi6EtSRwx9SerI/wdaA4XxGRtu6QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq7CNZjxEt8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "e7f151fc-065f-417f-e778-c462566a0aa3"
      },
      "source": [
        "print(\"distribution of test data in sentiments is shown in chart below\")\n",
        "\n",
        "testDataFrame['sentiment'].value_counts().plot(kind='bar')\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distribution of test data in sentiments is shown in chart below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff48b43c898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEaCAYAAADqqhd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUG4YQSNHW-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z-whWRzEgm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractTweetSentiment(df):\n",
        "  data = df.loc[:,['meta','sentiment']]\n",
        "  tempString = \"\"\n",
        "  ListOfTweet = []\n",
        "  ListOfSentiment = []\n",
        "  for i in range(data.shape[0]):\n",
        "    if(data.iloc[i,0]==\"meta\"):\n",
        "      ListOfTweet.append(tempString.strip())\n",
        "      ListOfSentiment.append(str(data.iloc[i,1]))\n",
        "      tempString=\"\"\n",
        "    else:\n",
        "      tempString += (str(data.iloc[i,0])+\" \")\n",
        "  ListOfTweet.append(tempString.strip())\n",
        "  return ListOfTweet[1:], ListOfSentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOvIID4bFwEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_list, y_train_list = extractTweetSentiment(trainDataFrame)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UtRo4UPF3RE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "5f0c6589-7228-4255-e14a-158c725c68ac"
      },
      "source": [
        "#examples\n",
        "import random \n",
        "for i in range(30):\n",
        "  rand = random.randint(1,500)\n",
        "  print(x_train_list[rand],y_train_list[rand],sep = \" sentiment = \")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ WaseemBadami @ iqrarulhassan We will miss the beautiful voice of # AmjadSabriShaheed Allah un k darjaat buland far ‚Ä¶ https // t . co / xf9FkUdfew sentiment = neutral\n",
            "@ Radha274402 nahi radha ji kaon kahta h ki bhagat singh chandrashekhar aajad jaise deshbhakt is dharati pe janm nhi ‚Ä¶ https // t co / Bx7D82EMXh sentiment = positive\n",
            "@ Chhoti _ Farmer Omg she's so beautiful üò≠ so dramatic sentiment = positive\n",
            "@ ChaBoyyHD Chaa .. Can ihave any cheap Ak ? Cuz Ak it's my Fav Weapon .. If u wan we can battle .. if i win u give me ‚Ä¶ https // t . co / xFDIrkRYpE sentiment = positive\n",
            "@ chitraaum Rassi Jal Gayi par bal nahi gayi EVM par Jor nahi chala to patrakar on ke kapde utaro Kuch To karna hai ‚Ä¶ https // t . co / a7FFl5cDIs sentiment = negative\n",
            "@ PiyushGoyal @ narendramodi Bahut bahut badhai AAP jaise logo ke Karan hi Modi ji Ko majboori Mili hai . isi tarah se ‚Ä¶ https // t . co / 0F8OK0aQIW sentiment = positive\n",
            "Aise barish se dosti a66i nahi maaraz tere khud ka gar mitti ka h Ku6 to khyal kar Tera intzar har koi nahi karega ‚Ä¶ https // t . co / VnzralLxAe sentiment = neutral\n",
            "@ MalboBagums Sari shairi tassali aur dilasay pay hi munhasir hoti hai .. warna shairi kyun karay koi agar pas ho kuch üòú sentiment = positive\n",
            "@ BaBoo _ sAhEb _ To Tera jat talbani Jess harqate kyu Kar tahe masum logo ko kyu Marta tab Tera ammi kaha Mar jate he ‚Ä¶ https // t . co / 74Zn3UNmDh sentiment = negative\n",
            "RT @ LukeEclair # FF Have a great weekend ! @ politicaldani @ Bhav _ Popat @ ConnorJonesCons @ ali _ panju @ theblondpond @ stephiebellabb @ MrRhysBenja ‚Ä¶ sentiment = positive\n",
            "RT @ Jiminthebiaswr1 @ Aslamsunia1 kya kahun me tumhare baray me Tu to meri jaan hr vheez mein do haath agy hai üòè I love you to Namjoon-I me ‚Ä¶ sentiment = positive\n",
            "@ Dr _ fizakhan # Pakistani girls photo without Pakistan ka karz Ada karo Pakistani girls for Heera Mandi Mein Bata Do ‚Ä¶ https // tco / YNyPUqUGo1 sentiment = neutral\n",
            "@ M _ AHMAD884 @ shahnaveid 1971 üòÇü§£ü§£ Lulli hoti nahi khadi Baten karalo badi badi https // t . co / NNkAZEEx3x sentiment = neutral\n",
            "@ narendramodi SIR APKO AUR BJP KO MERI TARAF SE JEET KI BAHUT BAHUT SUBHKAMNAYE APP DESH AUR UCHAIYO PAR LE JAYE P ‚Ä¶ https // t co / cUQYcRe8GM sentiment = positive\n",
            "@ Shahid _ shono @ Zeeshanpk01 üòÇüòÇüòÇ Exactly Tum jeeto yhh haro hmma tum sa pyar h pakistani team Bss india k mada mukabil aoo sentiment = positive\n",
            "@ IamHaseebAhmad @ majorgauravarya @ UN Ha ha ha . Cow mutr peeke we have won all wars against you guys . You should st ‚Ä¶ https // t . co / bcPtVRPMYc sentiment = neutral\n",
            "@ Abhishekkar _ CNBC ü§£ü§£ü§£ü§£ü§£ü§£ AKA sir ne to CNBC ke pahele bol diya tha https // t . co / h1rAzqIHs0 sentiment = neutral\n",
            "@ TigerNeelesh @ bittusempire Khud sharda chitfund ki ghotale ki pramukh waiti hain duaro ko daket bolti hain . Khud c ‚Ä¶ https // t . co / of3DbvdE3Z sentiment = negative\n",
            "@ phata _ dhol __ Seriously one of the best post i have seen . Bravo nd respect sentiment = positive\n",
            "@ mlkhattar Sir Congratulations on your marvellous victory @ BJP but it seems that no one is ever bothered about sev ‚Ä¶ https // t . co / 8woRVtJlvE sentiment = negative\n",
            "Desh ke gaddaro ke liye 5 saal bahut painful hoge kyoki Mota Bhai is now home minister of India üáÆüá≥ üí™üòúüòú https // t . co / H1CxoIOYzI sentiment = neutral\n",
            "@ zoo _ bear @ Atheist _ Krishna Zoo bear bhai .... tumara har jagah se kaat Gaya hai .... keep calm and start preparing for 2024... Good luck üëç sentiment = positive\n",
            "@ LKanath @ iishgroup @ rajeev _ mp @ VMBJP @ surendranbjp @ janamtelevision @ asianetnewstv üôè Jai modiji . jai . rss üáÆüá≥üáÆüá≥üö©üö©üå∑üå∑ https // t . co / VXu6jVQI0m sentiment = positive\n",
            "RT @ Being _ Zeeshan09 Love u Bhaijan ... Father + son .. # Bharat # IAmBharat BEST Pic From Entire # Promotions ... Mashallah üëå‚ô•üî• https // t . co / o6d ‚Ä¶ sentiment = positive\n",
            "I miss them we were a craze .. we used for them .. bas koi kuch galat bolde .. old memories https // t . co / NeN57fFIVM sentiment = neutral\n",
            "@ RubikaLiyaquat @ INCIndia Rubika Ji aap bhout badiya aur sach bolne wale Ho aap ek mahan anchor Ho aapke sath har ‚Ä¶ https // t co / SgJt2TqEkv sentiment = positive\n",
            "@ Serrial _ killer @ Baat _ Sunoo @ ThiMoiz I don't know whether it's correct news or wrong but pubg tou mein nai final sai kafi pehlay chor di thi sentiment = neutral\n",
            "@ snake _ truths Fouj Mulk nahi chala sakti ho sub se mazbut of munazam ha BUT ye Haram Khor Chor Jahil Bey Eman Siasa ‚Ä¶ https // t . co / YOi3xtAawU sentiment = negative\n",
            "RT @ KangWeli Ewe tante leny memek nya becek seru sape basah kasur nya haa üòÄüòÅüòÅ i love you tante leny üòòüòòüòòüòò tar kita ber cinta lgh tante leny ‚Ä¶ sentiment = positive\n",
            "Yeh toh kuch bhi Nahi hai 5june ke baad world cup bhi postpone ho jaYeGaa Bhai Ka stardom ‚ù§‚ù§ https // t . co / Q6RiDhYJje sentiment = neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZPxlcuQGkNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_list, y_test_list = extractTweetSentiment(testDataFrame)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_u1PtdCG3ci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "a689af65-df76-4f21-fe22-ffa13996a5c9"
      },
      "source": [
        "#examples for test set\n",
        "for i in range(30):\n",
        "  rand = random.randint(1,500)\n",
        "  print(x_test_list[rand],y_test_list[rand],sep = \" sentiment = \")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT @ anjaliicreation Bilal - yeh sab mujhpr rely kar rahe hai D fahad Abb toh saari industry tumpr rely karegi beta our boy making us ‚Ä¶ sentiment = negative\n",
            "@ Ustadjii oye hoye nikey dar eh te seedhi chaper hi hai ve tere moo te . main te sun v nahi sakda ab kahin abey se ‚Ä¶ https // t . co / sPJ739l3BN sentiment = positive\n",
            "Champions League final ke liye hamare Tottenham ke fan @ GappistanRadio ko all the best ) How are the nerves ? sentiment = neutral\n",
            "@ BJP4India @ narendramodi @ AmitShah Vijay to honi hi thi magar itani asha nahi thi . desh ki janta ko dhanyvad ki vir ‚Ä¶ https // t . co / PI47xCEzrH sentiment = positive\n",
            "@ India _ 4970 Tohin qki Mai tumhari tarif kabhi bhi nahi karungi qki tarif aapne se aachhe logo ki ki jati h or Mai t ‚Ä¶ https // t . co / 7nSFqUg727 sentiment = negative\n",
            "@ ArvindKejriwal AAP ka karyakarta to niswarth hai .. lekin aap to bahut bade swarthi ho .. karyakarta party ke liye k ‚Ä¶ https // t . co / 0B2PZYUq4U sentiment = negative\n",
            "RT @ MysticxLipstick For Scorpio their full potential not only includes success but actually feeling HAPPY . Happiness is something that S ‚Ä¶ sentiment = positive\n",
            "Sun be ghi ke .. ab to teri g faadunga suwar ke .. tu ek suwar ka hai ya kyi musalmaan teri ma mei ghuse the https // t . co / PbVDtPuM3f sentiment = negative\n",
            "RT @ anjaliicreation Bilal - yeh sab mujhpr rely kar rahe hai D fahad Abb toh saari industry tumpr rely karegi beta our boy making us ‚Ä¶ sentiment = negative\n",
            "Bhale hi India or Pakistan k beech cricket world cup ka match ho lekin dekhunga to m # JCBkiKhudaai hi So much fun ‚Ä¶ https // t co / xL6H2UYKiv sentiment = neutral\n",
            "RT @ hinasafi Ab ye chor $2000 ki drug bolkay funding laingay ( read KHAYENGAY ) aur $8 ki drug Australia se manga k dou chaar din Sindh main ‚Ä¶ sentiment = negative\n",
            "@ narendramodi adarniya MODI JI apko ek bar fir NEW INDIA ki kaman sambhalne k liye apko HARDIK SHUBHKAMANYE .... in 5‚Ä¶ https // t . co / DlrF0wSl4v sentiment = positive\n",
            "Bachpan se lekar ab tak aur aage bhi aap hi mere liye No . 1 rahenge sir @ SrBachchan ‚ù§Ô∏è‚ù§Ô∏è god bless you with good h ‚Ä¶ https // t . co / IXDkVgjoTq sentiment = positive\n",
            "RT @ Sandeep16049517 @ narendramodi Hamare desh ke asli hero Manniy @ Modi Ji Ko hardik badhai Aapki @ Jeet se aapse jada Mai @ khush hu kas ‚Ä¶ sentiment = positive\n",
            "Papu ko tavazo deni band ker dewey . Apney app saaff ho jayega . .. aakhir papu papu hay . Prove ker diya 2019 election ‚Ä¶ https // t . co / 0sKHK4T1sq sentiment = negative\n",
            "@ Xarar786 @ PakSarfrazbugti koch generals ky naam or corruption bhi mention ker daity koi data hy ya bsss sonni sonnai he chor rahy ho sentiment = neutral\n",
            "@ Ra _ Bies Tag @ AmitShah soniaraga + cong torturedthrowawaypunished by fake cases modi + shah + Gujarat ppl insulted is ‚Ä¶ https // t . co / RNupds8end sentiment = neutral\n",
            "Sahidon ke naam pe vote maang liye bjp walo ne sach to sab ke samne aa hi gaya .. Khud ki mi17 helicaptor khud hi a ‚Ä¶ https // t . co / BGDbXWksLd sentiment = negative\n",
            "Ye Ye ..... ye ??????? We gonna start another June on a sour note ? Uhhhh yes no yes ...... no ( yes ) sentiment = neutral\n",
            "@ DrKumarVishwas @ mlkhattar Kumar Vishwas ji aap ke pass agar khabar pahle aa gayi toh ak ache nagarik hone ke aate ‚Ä¶ https // t co / kHSSnvKO0Z sentiment = positive\n",
            "@ kanhaiyakumar Pakistan ki aulad sale Kanhaiya Kumar tere ko bhi Goli marunga behen chod Tere Jaisa Gaddar sale Ham ‚Ä¶ https // t co / nfJHXMToCc sentiment = positive\n",
            "RT @ lb1lalitabathej @ TamannaInsan15 @ ManishKasaur @ Ritika88255523 @ rajniiinsa7 Love u bhut saara sweetu papa sentiment = positive\n",
            "Sir ji 2007 world cup middle order me batting krne ka chance mila us time apka experience aur feeling Kya thA # SachinOpensAgain sentiment = neutral\n",
            "RT @ lb1lalitabathej @ TamannaInsan15 @ ManishKasaur @ Ritika88255523 @ rajniiinsa7 Love u bhut saara sweetu papa sentiment = positive\n",
            "@ DesiStupides @ kunalkamra88 Apne baap ki photo ko edit kar modi ka face chipka de toh man jau ke tu Ek baap ka paidaish hai sentiment = negative\n",
            "# GinsoyTeamExtreme khel kar 100000 jeetna hai üòÉ Aap bhi luck try kro aur compete with friends ‚Ä¶ https // t . co / 3nDf3TXOXe sentiment = neutral\n",
            "RT @ DimpleDoll777 @ Gurmeetramrahim Papa thnku thnku soooo much üòäüòä Eda hi rehmat bnae rkhyo sohne saai ji üòäüòôüòôüòôüòôüòô sentiment = positive\n",
            "RT @ NasirPasir Hanya orang yg betul2 pernah PATAH HATI je boleh feel lagu ni . Dengar lirik dia . Meremang guys üò≠ That moment bila finally ‚Ä¶ sentiment = neutral\n",
            "Champions League final ke liye hamare Tottenham ke fan @ GappistanRadio ko all the best ) How are the nerves ? sentiment = neutral\n",
            "RT @ MysticxLipstick For Scorpio their full potential not only includes success but actually feeling HAPPY . Happiness is something that S ‚Ä¶ sentiment = positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuNRr2-GIYov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1adab077-2f78-4d1d-c568-33e0257299d1"
      },
      "source": [
        "tknizer = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
        "tknizer.fit_on_texts(x_train_list)\n",
        "print(\"length of x_train_list is \",len(x_train_list))\n",
        "print(\"length of y_train_list is \",len(y_train_list))\n",
        "print(\"length of x_test_list is \",len(x_test_list))\n",
        "print(\"length of y_test_list is \",len(y_test_list))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of x_train_list is  13524\n",
            "length of y_train_list is  13524\n",
            "length of x_test_list is  1869\n",
            "length of y_test_list is  1869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h3ARRj9ItZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataFor_xTrain = tknizer.texts_to_sequences(x_train_list)\n",
        "dataFor_xTest = tknizer.texts_to_sequences(x_test_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oa70xmnI82i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y8QfXj_I_2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pad_sequences(dataFor_xTrain, maxlen=250, padding='post')\n",
        "X_test = pad_sequences(dataFor_xTest, maxlen=250, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0WPBqmbJJyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train, dtype='float32')\n",
        "X_test = np.array(X_test, dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lALNgrbNJOdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical as to_intt\n",
        "\n",
        "\n",
        "def convSentimentAsINT(list):\n",
        "  SentiAsINT = []\n",
        "  for i in list:\n",
        "    if(i == \"positive\"):\n",
        "      SentiAsINT.append(0)\n",
        "    elif(i == \"negative\"):\n",
        "      SentiAsINT.append(1)\n",
        "    else:\n",
        "      SentiAsINT.append(2)\n",
        "  \n",
        "  SentiAsINT = np.array(SentiAsINT,dtype='float32')\n",
        "  categoricalSentiments = to_intt(SentiAsINT)\n",
        "\n",
        "  return categoricalSentiments"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xCezcRaJTEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = convSentimentAsINT(y_train_list)\n",
        "Y_test = convSentimentAsINT(y_test_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXilRqI8JXz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c60dd3d-8775-4bef-ea02-193afcce4ec7"
      },
      "source": [
        "total_vacabulary = len(tknizer.word_index)\n",
        "print(\"size of the vocalbuary is \",total_vacabulary)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of the vocalbuary is  900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hT5jA82JcAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_weights = []\n",
        "\n",
        "for char, i in tknizer.word_index.items():\n",
        "    onehot = np.zeros(total_vacabulary)\n",
        "    onehot[i - 1] = 1\n",
        "    embedding_weights.append(onehot)\n",
        "\n",
        "embedding_weights = np.array(embedding_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJHyjZPMJhH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LSTM, Lambda, concatenate, TimeDistributed, Bidirectional\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Conv1D, GlobalMaxPool1D, Embedding, Flatten, Dense, Input, Dropout, MaxPooling1D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j7-FICVJm-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "42b1c664-150c-4181-f5c3-a993a2835195"
      },
      "source": [
        "overall_sentiments = 3\n",
        "embedding_size = total_vacabulary\n",
        "conv_layers = [[256, 7, 3],\n",
        "               [256, 7, 3],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, 3]]\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=total_vacabulary, output_dim=embedding_size, input_length = 250, weights=[embedding_weights]))\n",
        "\n",
        "for filter_num, filter_size, pooling_size in conv_layers:\n",
        "    model.add(Conv1D(filter_num, filter_size, activation='relu'))\n",
        "    if pooling_size != -1:\n",
        "        model.add(MaxPooling1D(pool_size=pooling_size))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=1024, activation='sigmoid'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=1024, activation='sigmoid'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=overall_sentiments, activation='softmax'))\n",
        "print(\"the following is the summary of the model\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 250, 900)          810000    \n",
            "_________________________________________________________________\n",
            "conv1d_37 (Conv1D)           (None, 244, 256)          1613056   \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 81, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 75, 256)           459008    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling (None, 25, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_39 (Conv1D)           (None, 23, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_40 (Conv1D)           (None, 21, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_41 (Conv1D)           (None, 19, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_42 (Conv1D)           (None, 17, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 5, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1024)              1311744   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 6,033,939\n",
            "Trainable params: 6,033,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-8b_vceVS4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Ffa7ogVXMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "753e8cd3-4c33-4b7f-f9d1-474f0c0bb88e"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=128, epochs=30, validation_data=(X_test, Y_test), verbose=1)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13524 samples, validate on 1869 samples\n",
            "Epoch 1/30\n",
            "13524/13524 [==============================] - 19s 1ms/step - loss: 1.2550 - acc: 0.3415 - val_loss: 1.0873 - val_acc: 0.4034\n",
            "Epoch 2/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 1.0614 - acc: 0.4242 - val_loss: 1.0490 - val_acc: 0.4254\n",
            "Epoch 3/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.9605 - acc: 0.5049 - val_loss: 0.9985 - val_acc: 0.4917\n",
            "Epoch 4/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.8950 - acc: 0.5643 - val_loss: 1.0139 - val_acc: 0.5088\n",
            "Epoch 5/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.8408 - acc: 0.6052 - val_loss: 1.0344 - val_acc: 0.4933\n",
            "Epoch 6/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.7880 - acc: 0.6428 - val_loss: 0.9874 - val_acc: 0.5292\n",
            "Epoch 7/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.7369 - acc: 0.6762 - val_loss: 1.0947 - val_acc: 0.5292\n",
            "Epoch 8/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.6246 - acc: 0.7423 - val_loss: 1.0997 - val_acc: 0.5211\n",
            "Epoch 9/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.5407 - acc: 0.7866 - val_loss: 1.1722 - val_acc: 0.5243\n",
            "Epoch 10/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.4419 - acc: 0.8347 - val_loss: 1.4092 - val_acc: 0.5142\n",
            "Epoch 11/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.3489 - acc: 0.8776 - val_loss: 1.4238 - val_acc: 0.5067\n",
            "Epoch 12/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.2981 - acc: 0.8976 - val_loss: 1.5965 - val_acc: 0.5297\n",
            "Epoch 13/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.2291 - acc: 0.9257 - val_loss: 1.6320 - val_acc: 0.5078\n",
            "Epoch 14/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.2140 - acc: 0.9336 - val_loss: 1.6467 - val_acc: 0.5265\n",
            "Epoch 15/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.1831 - acc: 0.9445 - val_loss: 1.8979 - val_acc: 0.5094\n",
            "Epoch 16/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.1540 - acc: 0.9547 - val_loss: 1.9366 - val_acc: 0.5078\n",
            "Epoch 17/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.1420 - acc: 0.9564 - val_loss: 2.0579 - val_acc: 0.5233\n",
            "Epoch 18/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.1313 - acc: 0.9598 - val_loss: 1.9424 - val_acc: 0.4944\n",
            "Epoch 19/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.1083 - acc: 0.9700 - val_loss: 2.1554 - val_acc: 0.5115\n",
            "Epoch 20/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0986 - acc: 0.9729 - val_loss: 2.0514 - val_acc: 0.5115\n",
            "Epoch 21/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.1143 - acc: 0.9656 - val_loss: 2.0831 - val_acc: 0.5227\n",
            "Epoch 22/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0947 - acc: 0.9709 - val_loss: 2.1259 - val_acc: 0.5072\n",
            "Epoch 23/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0970 - acc: 0.9712 - val_loss: 2.2665 - val_acc: 0.5110\n",
            "Epoch 24/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0936 - acc: 0.9717 - val_loss: 2.4236 - val_acc: 0.5056\n",
            "Epoch 25/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0808 - acc: 0.9757 - val_loss: 2.1237 - val_acc: 0.5136\n",
            "Epoch 26/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0623 - acc: 0.9821 - val_loss: 2.3981 - val_acc: 0.5163\n",
            "Epoch 27/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0665 - acc: 0.9814 - val_loss: 2.4915 - val_acc: 0.5217\n",
            "Epoch 28/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0623 - acc: 0.9828 - val_loss: 2.1852 - val_acc: 0.5115\n",
            "Epoch 29/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0608 - acc: 0.9834 - val_loss: 2.4844 - val_acc: 0.5147\n",
            "Epoch 30/30\n",
            "13524/13524 [==============================] - 17s 1ms/step - loss: 0.0655 - acc: 0.9806 - val_loss: 2.1557 - val_acc: 0.5099\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4841ae6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_IAMkj6Vejl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#computing precision recall and precision\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDvddemxbvnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1score = []\n",
        "recalls = []\n",
        "precisions = []\n",
        "accuracy = []\n",
        "\n",
        "predict = (np.array(model.predict(X_test))).round() \n",
        "targ = Y_test\n",
        "f1 = f1_score(targ, predict,average=None)\n",
        "recall = recall_score(targ, predict,average=None)\n",
        "precision = precision_score(targ, predict,average=None)\n",
        "accuracyy = accuracy_score(targ,predict)\n",
        "f1score.append(f1)\n",
        "recalls.append(recall)\n",
        "precisions.append(precision)\n",
        "accuracy.append(accuracyy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGexXrs0Jwnd",
        "colab_type": "text"
      },
      "source": [
        "Results (Accuracy, F1Score, Precision and Recall)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVe4K44vuIZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "be0725bb-1cfb-4424-9ba5-038f7935f82d"
      },
      "source": [
        "\n",
        "print(\"F1_positive is\",f1[0])\n",
        "print(\"F1_negative is\", f1[1])\n",
        "print(\"F1_Neutral is \", f1[2])\n",
        "print(\"The Accuracy of the model : \",accuracy)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_positive is 0.47405900305188203\n",
            "F1_negative is 0.5497797356828193\n",
            "F1_Neutral is  0.5049751243781093\n",
            "The Accuracy of the model :  [0.5088282504012841]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-grP4-1ul9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "501b2ae3-acf9-4bb0-9337-7bb15cb7e713"
      },
      "source": [
        "print(\"Precision_Positive is\", precision[0])\n",
        "print(\"Precision_Negative is\", precision[1])\n",
        "print(\"Precision_Neutral is\", precision[2])"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision_Positive is 0.5810473815461347\n",
            "Precision_Negative is 0.5182724252491694\n",
            "Precision_Neutral is 0.47540983606557374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64h_7kQrvDnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "59dc0337-c9c0-4892-a46c-3ee1518dd073"
      },
      "source": [
        "print(\"similarly recall_Positive\",recall[0])\n",
        "print(\"recall_negative is\",recall[1])\n",
        "print(\"recall_Neutral is\",recall[2])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similarly recall_Positive 0.40034364261168387\n",
            "recall_negative is 0.5853658536585366\n",
            "recall_Neutral is 0.5384615384615384\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}